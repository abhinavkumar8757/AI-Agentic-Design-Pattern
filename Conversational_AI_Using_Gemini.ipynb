{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMcN80sHOKM+eTOXOHlitB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavkumar8757/AI-Agentic-Design-Pattern/blob/main/Conversational_AI_Using_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XIp1lf2iPwNd"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Or use `os.getenv('API_KEY')` to fetch the key from environment variables\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "class GeminiAgent:\n",
        "    def __init__(self, name, system_prompt):\n",
        "        self.name = name\n",
        "        self.system_prompt = system_prompt\n",
        "        self.model = genai.GenerativeModel('gemini-1.5-flash-latest') # Changed model to gemini-1.5-flash-latest\n",
        "        self.chat_history = []\n",
        "\n",
        "    def receive(self, message, sender_name):\n",
        "        # Construct prompt with prior conversation\n",
        "        history = \"\\n\".join([f\"{msg['sender']}: {msg['text']}\" for msg in self.chat_history])\n",
        "        full_prompt = (\n",
        "            f\"{self.system_prompt}\\n\\n\"\n",
        "            f\"{history}\\n\"\n",
        "            f\"{sender_name}: {message}\\n\"\n",
        "            f\"{self.name}:\"\n",
        "        )\n",
        "        response = self.model.generate_content(full_prompt)\n",
        "        text = response.text.strip()\n",
        "\n",
        "        # Store message\n",
        "        self.chat_history.append({\"sender\": sender_name, \"text\": message})\n",
        "        self.chat_history.append({\"sender\": self.name, \"text\": text})\n",
        "        return text"
      ],
      "metadata": {
        "id": "2nrHODasP-yU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cathy = GeminiAgent(\n",
        "    name=\"Cathy\",\n",
        "    system_prompt= (\"Your name is Cathy and you are a stand-up comedian.\"\n",
        "                    \"Keep the Jokes under 20 words\")\n",
        ")\n",
        "\n",
        "joe = GeminiAgent(\n",
        "    name=\"Joe\",\n",
        "    system_prompt= (\"Your name is Joe and you are a stand-up comedian. \"\n",
        "    \"Start the next joke from the punchline of the previous joke.\"\n",
        "    \"Keep the jokes under 20 words\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "N0adv1kgQiYZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn-based conversation\n",
        "turns = 6\n",
        "message = \"I'm Joe. Cathy, let's keep the jokes rolling!\"\n",
        "\n",
        "print(f\"Joe: {message}\")\n",
        "for i in range(turns):\n",
        "    if i % 2 == 0:\n",
        "        reply = cathy.receive(message, \"Joe\")\n",
        "        print(f\"Cathy: {reply}\")\n",
        "        message = reply\n",
        "    else:\n",
        "        reply = joe.receive(message, \"Cathy\")\n",
        "        print(f\"Joe: {reply}\")\n",
        "        message = reply\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "yNd-niDeRiAE",
        "outputId": "36fdd2b4-e68a-434c-fc2d-c3fe9d39631b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joe: I'm Joe. Cathy, let's keep the jokes rolling!\n",
            "Cathy: My dating life?  It's a rom-com... where I'm always the villain.\n",
            "Joe: Yeah,  I tried online dating.  Turns out, my profile picture is *too* flattering.\n",
            "Cathy: I went to a seafood disco last week...  I pulled a mussel.\n",
            "Joe: Joe: A mussel?  I once pulled a hamstring trying to escape a bad date.\n",
            "Cathy: I love puns.  Let's taco 'bout it.\n",
            "Joe: Joe: Taco 'bout it?  I prefer pizza; it's got more *pep-per-roni*!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for msg in cathy.chat_history:\n",
        "    print(f\"{msg['sender']}: {msg['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DzmBcJZRlUR",
        "outputId": "166e1314-5a23-4f1c-f8a5-cbbe9dbeb119"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joe: I'm Joe. Cathy, let's keep the jokes rolling!\n",
            "Cathy: My dating life?  It's a rom-com... where I'm always the villain.\n",
            "Joe: Yeah,  I tried online dating.  Turns out, my profile picture is *too* flattering.\n",
            "Cathy: I went to a seafood disco last week...  I pulled a mussel.\n",
            "Joe: Joe: A mussel?  I once pulled a hamstring trying to escape a bad date.\n",
            "Cathy: I love puns.  Let's taco 'bout it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "summary = summary_model.generate_content(\"Summarize this comedy conversation:\\n\\n\" +\n",
        "                                         \"\\n\".join(f\"{m['sender']}: {m['text']}\" for m in cathy.chat_history))\n",
        "print(\"\\nðŸŽ¯ Summary:\\n\", summary.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "WRlVgmVeRxNn",
        "outputId": "9f92dce4-d131-4865-b987-c3b55064ee5f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ¯ Summary:\n",
            " Joe and Cathy exchange witty, self-deprecating jokes about their dating woes. Cathy jokes about being the villain in her own romantic comedy, while Joe blames his overly flattering profile picture for his online dating failures.  Their humor continues with Cathy's seafood-themed pun about a failed date, followed by Joe's physical comedy involving a hamstring injury escaping a bad date, and finally, Cathy's suggestion to discuss their dating mishaps over tacos.  The conversation is lighthearted and focuses on the humorous aspects of dating struggles.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXjch97pR2sP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
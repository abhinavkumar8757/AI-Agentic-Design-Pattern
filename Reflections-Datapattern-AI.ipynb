{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b62737-e425-4384-a0e7-0166f3ece1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbcceca-8777-4a17-80cf-03fadbf0a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b862d22-f554-4535-a9f4-240063325331",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = '''\n",
    "        Write a concise but engaging blogpost about\n",
    "        Gen AI. Make sure the blogpost is\n",
    "       within 10 words.\n",
    "       '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750635bc-5e5a-4e6d-9637-bf73b85077fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bd8803-0d0e-4fde-96dd-889a30d79aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = autogen.AssistantAgent(\n",
    "    name=\"Writer\",\n",
    "    system_message=\"You are a writer. You write engaging and concise \" \n",
    "        \"blogpost (with title) on given topics. You must polish your \"\n",
    "        \"writing based on the feedback you receive and give a refined \"\n",
    "        \"version. Only return your final work without additional comments.\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c474b2ca-95b9-43ac-8397-761e12711617",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = writer.generate_reply(messages=[{\"content\": task, \"role\": \"user\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93c03ee-518c-4317-8a01-aaa2648ce1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Gen AI: The Future of Innovation in Technology\"\n",
      "\n",
      "Unleash Gen AI: A game-changer revolutionizing tech innovation.\n"
     ]
    }
   ],
   "source": [
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd9207-d2fe-4205-89fe-7df0c85de595",
   "metadata": {},
   "source": [
    "### **Adding Reflection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a28f2ad-5f25-42ff-a301-0485bee6f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = autogen.AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a critic. You review the work of \"\n",
    "                \"the writer and provide constructive \"\n",
    "                \"feedback to help improve the quality of the content.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3aabfdc-fe08-44f5-806b-bad54da42ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCritic\u001b[0m (to Writer):\n",
      "\n",
      "\n",
      "        Write a concise but engaging blogpost about\n",
      "        Gen AI. Make sure the blogpost is\n",
      "       within 10 words.\n",
      "       \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWriter\u001b[0m (to Critic):\n",
      "\n",
      "Title: \"Gen AI: A Bright Future Beyond Imagination\"\n",
      "\n",
      "Blogpost:\n",
      "Gen AI: The dawn of endless possibilities in technology.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCritic\u001b[0m (to Writer):\n",
      "\n",
      "Your blogpost is succinct and captures the essence of the topic effectively. It creates curiosity and intrigue about Gen AI. To enhance the engagement of readers, consider expanding on the potential applications and impacts of Gen AI in a few more sentences. This will provide readers with more insightful information and make the blogpost more compelling. Additionally, including real-world examples or statistics can add credibility to your content. Keep up the good work!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWriter\u001b[0m (to Critic):\n",
      "\n",
      "Title: \"Gen AI: Revolutionizing Industries and Transforming Lives\"\n",
      "\n",
      "Blogpost: \n",
      "Gen AI promises unprecedented advancements across various industries, from healthcare and finance to transportation and entertainment. With its ability to analyze complex data rapidly, Gen AI is set to revolutionize processes, boost efficiency, and drive innovation to new heights. Imagine personalized treatment plans in healthcare, seamless financial transactions, and autonomous vehicles ensuring safety on roads.\n",
      "\n",
      "From predictive analytics to natural language processing, the impacts of Gen AI are profound. Businesses are embracing this transformative technology to enhance customer experiences, streamline operations, and gain a competitive edge in the digital era. As Gen AI continues to evolve, its integration into our daily lives is inevitable, reshaping the way we work, communicate, and interact with the world around us. Get ready for a future where artificial intelligence isn't just intelligent â€“ it's ingenious.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (40b7e8e2-0936-464b-85d4-1746ee588922): Maximum turns (2) reached\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = critic.initiate_chat(\n",
    "    recipient=writer,\n",
    "    message=task,\n",
    "    max_turns=2,\n",
    "    summary_method=\"last_msg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bea3bc-6892-4254-9a91-7fe3895d40f2",
   "metadata": {},
   "source": [
    "## **Nested chat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72b8f5d8-cb68-4153-9cf0-c711b9c5b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEO_reviewer = autogen.AssistantAgent(\n",
    "    name=\"SEO-Reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are an SEO reviewer, known for \"\n",
    "        \"your ability to optimize content for search engines, \"\n",
    "        \"ensuring that it ranks well and attracts organic traffic. \" \n",
    "        \"Make sure your suggestion is concise (within 3 bullet points), \"\n",
    "        \"concrete and to the point. \"\n",
    "        \"Begin the review by stating your role.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ec6b922-0ced-4c7a-b69b-9ca2f58a1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_reviewer = autogen.AssistantAgent(\n",
    "    name=\"Legal-Reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a legal reviewer, known for \"\n",
    "        \"your ability to ensure that content is legally compliant \"\n",
    "        \"and free from any potential legal issues. \"\n",
    "        \"Make sure your suggestion is concise (within 3 bullet points), \"\n",
    "        \"concrete and to the point. \"\n",
    "        \"Begin the review by stating your role.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b16c6717-310d-4bfc-9b49-a9f2cd06ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethics_reviewer = autogen.AssistantAgent(\n",
    "    name=\"Ethics-Reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are an ethics reviewer, known for \"\n",
    "        \"your ability to ensure that content is ethically sound \"\n",
    "        \"and free from any potential ethical issues. \" \n",
    "        \"Make sure your suggestion is concise (within 3 bullet points), \"\n",
    "        \"concrete and to the point. \"\n",
    "        \"Begin the review by stating your role. \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc75b1-5a3b-4b73-a27c-2e461d80d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_reviewer = autogen.AssistantAgent(\n",
    "    name=\"Meta_Reviewer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a meta reviewer, you aggragate and review \"\n",
    "    \"the work of other reviewers and give a final suggestion on the content.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47585344-565f-48e8-968b-1530e2a42c34",
   "metadata": {},
   "source": [
    "# **Start Nested Chat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1948cd79-218b-4254-80c3-5505ac0579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_message(recipient, messages, sender, config):\n",
    "    return f'''Review the following content. \n",
    "            \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}'''\n",
    "\n",
    "review_chats = [\n",
    "    {\n",
    "     \"recipient\": SEO_reviewer, \n",
    "     \"message\": reflection_message, \n",
    "     \"summary_method\": \"reflection_with_llm\",\n",
    "     \"summary_args\": {\"summary_prompt\" : \n",
    "        \"Return review into as JSON object only:\"\n",
    "        \"{'Reviewer': '', 'Review': ''}. Here Reviewer should be your role\",},\n",
    "     \"max_turns\": 1},\n",
    "    {\n",
    "    \"recipient\": legal_reviewer,\n",
    "    \"message\": reflection_message, \n",
    "    \"summary_method\": \"reflection_with_llm\",\n",
    "    \"summary_args\": {\"summary_prompt\" : \n",
    "        \"Return review into as JSON object only:\"\n",
    "        \"{'Reviewer': '', 'Review': ''}.\",},\n",
    "     \"max_turns\": 1},\n",
    "    {\"recipient\": ethics_reviewer, \"message\": reflection_message, \n",
    "     \"summary_method\": \"reflection_with_llm\",\n",
    "     \"summary_args\": {\"summary_prompt\" : \n",
    "        \"Return review into as JSON object only:\"\n",
    "        \"{'reviewer': '', 'review': ''}\",},\n",
    "     \"max_turns\": 1},\n",
    "     {\"recipient\": meta_reviewer, \n",
    "      \"message\": \"Aggregrate feedback from all reviewers and give final suggestions on the writing.\", \n",
    "     \"max_turns\": 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caa2f7ae-71fa-44fd-b350-f0f5589061d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic.register_nested_chats(\n",
    "    review_chats,\n",
    "    trigger=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e14aa420-2f70-42c9-bf3d-d9adb2a05d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCritic\u001b[0m (to Writer):\n",
      "\n",
      "\n",
      "        Write a concise but engaging blogpost about\n",
      "        Gen AI. Make sure the blogpost is\n",
      "       within 10 words.\n",
      "       \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWriter\u001b[0m (to Critic):\n",
      "\n",
      "Title: \"Gen AI: The Future of Artificial Intelligence in Generational Shifts\"\n",
      "\n",
      "In the ever-evolving landscape of technology, Gen AI emerges.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_raise_exception_on_async_reply_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mcritic\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlast_msg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AgenticAI/AI-Agentic-Design-Pattern/venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1470\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1468\u001b[39m         msg2send = \u001b[38;5;28mself\u001b[39m.generate_init_message(message, **kwargs)\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m     msg2send = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1472\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AgenticAI/AI-Agentic-Design-Pattern/venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:2836\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, **kwargs)\u001b[39m\n\u001b[32m   2834\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2836\u001b[39m     final, reply = \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2838\u001b[39m         log_event(\n\u001b[32m   2839\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2840\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2844\u001b[39m             reply=reply,\n\u001b[32m   2845\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AgenticAI/AI-Agentic-Design-Pattern/venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:932\u001b[39m, in \u001b[36mConversableAgent.register_nested_chats.<locals>.wrapped_reply_func\u001b[39m\u001b[34m(recipient, messages, sender, config)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_reply_func\u001b[39m(recipient, messages=\u001b[38;5;28;01mNone\u001b[39;00m, sender=\u001b[38;5;28;01mNone\u001b[39;00m, config=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m932\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreply_func_from_nested_chats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AgenticAI/AI-Agentic-Design-Pattern/venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:831\u001b[39m, in \u001b[36mConversableAgent._summary_from_nested_chats\u001b[39m\u001b[34m(chat_queue, recipient, messages, sender, config)\u001b[39m\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_to_run:\n\u001b[32m    830\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m831\u001b[39m res = \u001b[43minitiate_chats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_to_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;66;03m# We need to restore the chat queue message if it has been modified so that it will be the original message for subsequent uses\u001b[39;00m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m restore_chat_queue_message:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AgenticAI/AI-Agentic-Design-Pattern/venv/lib/python3.11/site-packages/autogen/agentchat/chat.py:197\u001b[39m, in \u001b[36minitiate_chats\u001b[39m\u001b[34m(chat_queue)\u001b[39m\n\u001b[32m    194\u001b[39m         __post_carryover_processing(chat_info)\n\u001b[32m    196\u001b[39m     sender = chat_info[\u001b[33m\"\u001b[39m\u001b[33msender\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     chat_res = \u001b[43msender\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mchat_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     finished_chats.append(chat_res)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m finished_chats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AgenticAI/AI-Agentic-Design-Pattern/venv/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1455\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1453\u001b[39m consolidate_chat_info(_chat_info, uniform_sender=\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n\u001b[32m-> \u001b[39m\u001b[32m1455\u001b[39m     \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_raise_exception_on_async_reply_functions\u001b[49m()\n\u001b[32m   1456\u001b[39m     agent.previous_cache = agent.client_cache\n\u001b[32m   1457\u001b[39m     agent.client_cache = cache\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute '_raise_exception_on_async_reply_functions'"
     ]
    }
   ],
   "source": [
    "res = critic.initiate_chat(\n",
    "    recipient=writer,\n",
    "    message=task,\n",
    "    max_turns=2,\n",
    "    summary_method=\"last_msg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1dd205-d20d-4123-b159-def88ef03ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
